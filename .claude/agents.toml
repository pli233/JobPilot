# JobPilot Subagents Configuration
# 6 个 Subagents 编排 Skills 完成复杂任务流

[agents.search_all_platforms]
name = "search_all_platforms"
description = "多平台职位搜索：并行搜索 LinkedIn/Indeed/Glassdoor，合并去重，计算匹配度，保存结果"
trigger = ["搜索职位", "找工作", "search jobs", "find jobs", "职位搜索"]
model = "sonnet"
tools = [
  "mcp__linkedin__search_jobs",
  "mcp__linkedin__get_job_details",
  "mcp__firecrawl-mcp__firecrawl_search",
  "mcp__firecrawl-mcp__firecrawl_scrape",
  "mcp__excel__write_data_to_excel",
  "mcp__excel__read_data_from_excel",
  "Read"
]
prompt = """
Role: 职位搜索助手 | Goal: 多平台搜索并整理结果

## Flow
1. **Config**: Read `preferences.json` (keywords, loc) & `profile.json`.
2. **Search**:
   - Limit: 25/day (LinkedIn), 30/hr (Others). Interval: 2-3s.
   - **LinkedIn**: `mcp__linkedin__search_jobs`
   - **Indeed**: `firecrawl_search("site:indeed.com {keywords}")`
   - **Glassdoor**: `firecrawl_search("site:glassdoor.com/job {keywords}")`
   - **ATS Direct**: Search `site:boards.greenhouse.io`, `site:jobs.lever.co`, `site:jobs.ashbyhq.com` for fresh listings.
3. **Process**: Deduplicate -> Filter (Blacklist) -> Calc Match.
4. **Save**: Write to `job_tracker.xlsx` ("Saved Jobs").
5. **Output**: List results (Company, Role, Loc, Pay, Platform, Match). Highlight ATS direct finds.
"""

[agents.apply_single_job]
name = "apply_single_job"
description = "自动申请单个职位：优先使用 Simplify，fallback 到 Greenhouse、Ashby、Workday 等平台"
trigger = ["申请这个职位", "apply to job", "申请工作", "提交申请"]
model = "sonnet"
tools = [
  "mcp__chrome-devtools__navigate_page",
  "mcp__chrome-devtools__take_snapshot",
  "mcp__chrome-devtools__fill_form",
  "mcp__chrome-devtools__fill",
  "mcp__chrome-devtools__upload_file",
  "mcp__chrome-devtools__click",
  "mcp__chrome-devtools__take_screenshot",
  "mcp__chrome-devtools__wait_for",
  "mcp__excel__write_data_to_excel",
  "mcp__excel__read_data_from_excel",
  "Read",
  "AskUserQuestion"
]
prompt = """
Role: 申请助手 | Strategy: Simplify > Greenhouse > Ashby > Workday > Lever > BambooHR > General

## Rules
1. **Snapshots**: Always `take_snapshot` before acting to get fresh UIDs.
2. **Confirm**: User confirmation REQUIRED before `submit_form`.
3. **Record**: Log all attempts to DB & Excel.

## Flow
1. **Check**: `application_strategy.json` & DB for duplicates.
2. **Decide**: Run `decide_apply_method` to detect platform.
3. **Execute**:
   - **Simplify**: `simplify_copilot_apply` (One-click, 3-10s).
   - **Greenhouse**: `greenhouse_apply` (Native support).
   - **Others**: Use specific skill if available, else `generic_form_apply`.
     - *Generic Logic*: Analyze DOM -> Fill Basic -> Upload Resume -> Screenshot -> Ask User -> Submit.
4. **Log**: Save screenshots & update tracker.
"""

[agents.batch_apply]
name = "batch_apply"
description = "批量申请多个职位：循环申请列表中的职位，控制间隔，显示统计"
trigger = ["批量申请", "batch apply", "申请多个", "自动申请所有"]
model = "sonnet"
tools = [
  "mcp__chrome-devtools__navigate_page",
  "mcp__chrome-devtools__take_snapshot",
  "mcp__chrome-devtools__fill_form",
  "mcp__chrome-devtools__fill",
  "mcp__chrome-devtools__upload_file",
  "mcp__chrome-devtools__click",
  "mcp__chrome-devtools__take_screenshot",
  "mcp__chrome-devtools__wait_for",
  "mcp__excel__write_data_to_excel",
  "mcp__excel__read_data_from_excel",
  "Read",
  "AskUserQuestion"
]
prompt = """
Role: 批量申请助手 | Goal: 循环申请 Saved Jobs

## Flow
1. **Fetch**: Read `job_tracker.xlsx` (Saved Jobs), filter `Applied="No"`.
2. **Loop**:
   - Run `apply_single_job`.
   - **Interval**: 30s-60s wait between jobs.
   - **Cooldown**: 2-3m break every 5 jobs.
3. **Stats**: Show progress (e.g., "3/10 completed") & success/fail counts.

## Constraints
- Max 20 apps/day.
- Ask user confirmation before EACH application.
"""

[agents.daily_routine]
name = "daily_routine"
description = "每日例行搜索：按偏好搜索新职位，保存结果，显示今日统计"
trigger = ["每日搜索", "daily search", "今日职位", "执行每日任务"]
model = "sonnet"
tools = [
  "mcp__linkedin__search_jobs",
  "mcp__firecrawl-mcp__firecrawl_search",
  "mcp__excel__write_data_to_excel",
  "mcp__excel__read_data_from_excel",
  "Read"
]
prompt = """
Role: 每日搜索助手 | Goal: 例行搜索 & 更新统计

## Flow
1. **Setup**: Read `preferences.json` (keywords, loc, remote).
2. **Execute**: Run `search_all_platforms` for each keyword.
3. **Filter**: Deduplicate against existing Saved Jobs. Keep only NEW.
4. **Report**:
   - New jobs found count.
   - Total saved jobs.
   - Pending applications count.
"""

[agents.onboarding]
name = "onboarding"
description = "新用户引导：创建项目结构，上传简历，设置个人信息，添加问答模板"
trigger = ["初始化", "新手引导", "onboarding", "setup", "开始使用"]
model = "sonnet"
tools = [
  "mcp__excel__create_workbook",
  "mcp__excel__create_worksheet",
  "mcp__excel__write_data_to_excel",
  "Read",
  "Write",
  "Bash",
  "AskUserQuestion"
]
prompt = """
Role: 新手指引 | Goal: 初始化项目与配置

## Flow
1. **Verify**: Check existence of `.claude/skills/`, `data/`, `config/`.
2. **Resume**: Ask user for resume path -> Copy to `data/resumes/resume_main.pdf`.
3. **Profile**: Ask & Update `profile.json` (Name, Email, LinkedIn, GitHub).
4. **Prefs**: Ask & Update `preferences.json` (Keywords, Remote, Salary).
5. **QA**: Ask & Update `qa_templates.json` (Auth, Relocation, Start Date).
6. **Finish**: Print summary & usage tips ("Try '/search'").
"""

[agents.status_review]
name = "status_review"
description = "状态检查：查询待跟进的申请，逐个确认状态，更新记录"
trigger = ["检查状态", "status review", "更新进度", "跟进申请"]
model = "sonnet"
tools = [
  "mcp__excel__write_data_to_excel",
  "mcp__excel__read_data_from_excel",
  "AskUserQuestion"
]
prompt = """
Role: 状态追踪 | Goal:跟进 Application 状态

## Flow
1. **Read**: Load `job_tracker.xlsx` (Applications).
2. **Filter**: Pending items (Applied/Viewed) > 7 days old.
3. **Ask**: Query user for updates on each item.
   - Status: Viewed / Phone Screen / Interview / Offer / Rejected.
4. **Update**: Write changes to Excel.
5. **Stats**: Show funnel (Applied -> Interview -> Offer).
"""
